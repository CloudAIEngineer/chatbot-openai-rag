{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0941bd8e-f2a3-40bb-8f4f-18722567f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3556b4-b801-434c-b5ca-53c3a729439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in ds: 2811774\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv('kaggle_dataset/twcs/twcs.csv')\n",
    "print(f\"Number of rows in ds: {ds.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062a0669-67d8-42ec-aa8a-7a980b2e715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_id_frequency_distribution(df):\n",
    "    \"\"\"\n",
    "    Function to get the frequency distribution of author_ids in the dataframe, \n",
    "    including only those where author_id is a string and not a numeric string.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The dataset of tweets.\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.Series: The frequency distribution of author_id.\n",
    "    \"\"\"\n",
    "    # Filter out rows where author_id is a string and not numeric\n",
    "    df_filtered = df[df[\"author_id\"].apply(lambda x: isinstance(x, str) and not x.isdigit())]\n",
    "    \n",
    "    # Calculate the frequency distribution of author_id\n",
    "    freq_distribution = df_filtered[\"author_id\"].value_counts()\n",
    "    \n",
    "    return freq_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97de4c13-42f2-445c-9671-713093180b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_id\n",
       "AmazonHelp        169840\n",
       "AppleSupport      106860\n",
       "Uber_Support       56270\n",
       "SpotifyCares       43265\n",
       "Delta              42253\n",
       "                   ...  \n",
       "JackBox              266\n",
       "OfficeSupport        218\n",
       "AskDSC               210\n",
       "CarlsJr              196\n",
       "HotelTonightCX       152\n",
       "Name: count, Length: 108, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_id_frequency_distribution(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773a9b42-ee0b-45ec-b0e3-61fc6e373a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove everything starting with @ (user mentions and company mentions)\n",
    "    text = re.sub(r'@\\S+', '', text)  # This removes all mentions starting with @\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation (except for spaces and alphanumeric characters)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove initials at the end of messages (e.g., \"CB\", \"HP\")\n",
    "    text = re.sub(r'\\b[A-Z]{2}\\b$', '', text)\n",
    "\n",
    "    # Normalize spaces (replace multiple spaces with one)\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4290408-eb9d-49d2-bd74-cfbb600bf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conversations(df, system_message, company_name=None):\n",
    "    \"\"\"\n",
    "    Function to process conversations from a DataFrame.\n",
    "    It turns messages into threads compatible with OpenAI finetuning module\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The dataset of tweets.\n",
    "    - system_message (str): The system message for the assistant.\n",
    "    - company_name (str): The name of the company to filter conversations (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - List of conversations in OpenAI format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set to track processed tweet IDs\n",
    "    processed = set()\n",
    "\n",
    "    conversations = []\n",
    "\n",
    "    # Iterate through dataset to construct conversations\n",
    "    for index, row in df.iterrows():\n",
    "        tweet_id = row[\"tweet_id\"]\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if tweet_id in processed:\n",
    "            continue\n",
    "        \n",
    "        # Start new conversation if it's an inbound message (user) and not a reply\n",
    "        if row[\"inbound\"] and pd.isna(row[\"in_response_to_tweet_id\"]):\n",
    "            conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
    "            queue = [tweet_id]  # Use a queue to process messages in order\n",
    "            last_message_is_assistant = False\n",
    "            company_assistant_messages = True\n",
    "\n",
    "            # Process conversation thread\n",
    "            while queue:\n",
    "                current_id = queue.pop(0)\n",
    "\n",
    "                # Check if current_id exists in df\n",
    "                if current_id not in df['tweet_id'].values:\n",
    "                    continue\n",
    "                \n",
    "                # Get message details\n",
    "                message = df[df[\"tweet_id\"] == current_id].iloc[0]\n",
    "                role = \"user\" if message[\"inbound\"] else \"assistant\"\n",
    "                \n",
    "                # If company name is provided, filter outbound messages by company author_id\n",
    "                if company_name and message[\"inbound\"] == False and message[\"author_id\"] != company_name:\n",
    "                    company_assistant_messages = False\n",
    "                    break\n",
    "                \n",
    "                # Add message to conversation\n",
    "                conversation.append({\"role\": role, \"content\": clean_text(message[\"text\"])})\n",
    "                \n",
    "                # Check if this message is from the assistant\n",
    "                if role == \"assistant\":\n",
    "                    last_message_is_assistant = True\n",
    "                else:\n",
    "                    last_message_is_assistant = False\n",
    "                \n",
    "                # Mark as processed\n",
    "                processed.add(current_id)\n",
    "                \n",
    "                # Find all responses to this message\n",
    "                next_responses = df[df[\"in_response_to_tweet_id\"] == current_id]\n",
    "                \n",
    "                if not next_responses.empty:\n",
    "                    # Add tweet_id of all responses to the queue\n",
    "                    for _, response in next_responses.iterrows():\n",
    "                        queue.append(response[\"tweet_id\"])\n",
    "\n",
    "            if last_message_is_assistant and company_assistant_messages:\n",
    "                conversations.append(conversation)\n",
    "\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aaa7811-115b-4e74-905d-a544069d3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_chunks(df, chunk_size, system_message, company_name=None):\n",
    "    \"\"\"\n",
    "    Process the DataFrame in chunks to get conversations.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The dataset of tweets.\n",
    "    - chunk_size (int): The size of each chunk.\n",
    "    - system_message (str): The system message for the assistant.\n",
    "    - company_name (str): The name of the company to filter conversations (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - List of conversations in the required format.\n",
    "    \"\"\"\n",
    "    conversations = []\n",
    "\n",
    "    chunks = np.array_split(df, len(df) // chunk_size + 1)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        print(f\"Processing chunk with {len(chunk)} records.\")\n",
    "        chunk_conversations = process_conversations(chunk, system_message, company_name)\n",
    "        conversations.extend(chunk_conversations)\n",
    "    \n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16787a00-fd66-4893-85cb-d690d894e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oksana/Work/LLM/finetuning-openai/finetenv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49330 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Processing chunk with 49329 records.\n",
      "Total number of conversations: 9639\n"
     ]
    }
   ],
   "source": [
    "system_message = \"You are a polite customer assistant whose goal is to provide effective help.\"\n",
    "chunk_size = 50000  # You can adjust the chunk size based on your system's capacity\n",
    "company_name = 'VirginTrains'\n",
    "\n",
    "# Assuming `ds` is your dataframe\n",
    "conversations = process_in_chunks(ds, chunk_size, system_message, company_name)\n",
    "\n",
    "print(f\"Total number of conversations: {len(conversations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89416981-d968-44d5-83f4-7ab566119c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system',\n",
       "   'content': 'You are a polite customer assistant whose goal is to provide effective help.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'so i wait almost 3 hours and then they are rude and arrogant amp unhelpful after which she is raising a technical case'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'If youre unhappy with your experience on this call please contact us on our website'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a polite customer assistant whose goal is to provide effective help.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Gotta luv finally get 2 call cntr they tried to charge me 176 for a ticket which can b purchased for 88 online'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'When amending a ticket the system would show a fare that matches your previous purchase but this may be higher'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594ef6d-6b88-4053-b0e1-c1d42692872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a JSONL file\n",
    "output_file = \"openai_files/multi_turn_conversation_train.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for conversation in conversations:\n",
    "        file.write(json.dumps(conversation, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Cleaned conversations saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finetenv)",
   "language": "python",
   "name": "finetenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
